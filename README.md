Reprogramming of Neural Networks: A New and Improved Machine Learning
Technique

Deep neural networks have achieved impressive performance on many complex tasks including
computer vision; however, they are difficult to train and also are susceptible to adversarial attacks
including reprogramming. Adversarial attacks can significantly degrade model accuracy and can
render even state of the art neural nets useless. Previous recent work has shown that neural nets
can not only be attacked with adversarial examples causing misclassifications, but can also be
”reprogrammed” to perform different tasks than they were trained for.
We introduce new and improved reprogramming technique that achieves better accuracy and
scalability, and compared to previous works can be successfully applied to more complex tasks.
We show that our method yields significantly more accurate models than models with the same
hyperparameters trained from scratch. In addition to that, our method also works well when
applied to small training datasets. Therefore, we argue that even though reprogramming can be
used maliciously, it does not have to be solely adversarial. Our reprogramming method allows for
re-using existing (pre)trained models and easily reprogramming them to perform new tasks. This
technique requires a lot less effort and hyperparameter tuning compared training new models from
scratch. Therefore, we believe that our improved and scalable reprogramming method has a great
potential to become a new method for creating machine learning models.
